[tool.poetry]
name = "llama2-server-docker-gpu"
version = "0.1.0"
description = ""
authors = ["Zbigniew Tomanek <tomanek@zbeegnew.dev>"]
license = "Apache 2.0"
readme = "README.md"
packages = [{include = "llama2_server"}]

[tool.poetry.dependencies]
python = "^3.9"
huggingface-hub = "^0.16.4"
joblib = "^1.3.1"

[tool.poetry.group.dev.dependencies]
black = "^23.7.0"
typer = "^0.9.0"
llama-cpp-python = {extras = ["server"], version = "^0.1.77"}

[tool.poetry.scripts]
llama-cli = "llama2_server.cli:app"

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"
